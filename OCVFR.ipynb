{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto IA Reconocimiento Facial con OpenCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Face_train():\n",
    "    cwd = Path().resolve()\n",
    "    #BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(cwd))\n",
    "    #print(cwd)\n",
    "    image_dir = os.path.join(BASE_DIR, \"OCVFR/images\")\n",
    "    print(image_dir)\n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier('cascade/data/haarcascade_frontalface_default.xml')\n",
    "    face_cascade2 = cv2.CascadeClassifier('cascade/data/haarcascade_frontalface_alt2.xml')\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create(radius=1, neighbors=8, grid_x=8, grid_y=8)##OpenCV Recognizer\n",
    "\n",
    "\n",
    "\n",
    "    current_id = 0\n",
    "    label_ids = {}\n",
    "    y_labels = []\n",
    "    x_train= []\n",
    "\n",
    "    for root, dirs, files in os.walk(image_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\"png\") or file.endswith(\"jpg\") or file.endswith(\"JPEG\"):\n",
    "                path = os.path.join(root,file)\n",
    "                label = os.path.basename(root).replace(\" \",\"_\").lower()\n",
    "                #print(label,path)\n",
    "\n",
    "                if not label in label_ids:\n",
    "                    label_ids[label] = current_id\n",
    "                    current_id +=1\n",
    "                id_ = label_ids[label]\n",
    "                #print(label_ids)\t\n",
    "                #x_train.append(path)\n",
    "                #y_labels.append(label)\n",
    "\n",
    "                pil_image = Image.open(path).convert(\"L\") #grayscale\n",
    "                size = (550,550)\n",
    "                final_image =pil_image.resize(size, Image.ANTIALIAS) #Ajuste de fotos\n",
    "                image_array = np.array(final_image, \"uint8\") #datos de las imagenes para entrenar\n",
    "                #print(image_array)\n",
    "                faces = face_cascade.detectMultiScale(image_array, scaleFactor=1.5, minNeighbors=5)\n",
    "                #print(faces)\n",
    "\n",
    "                for (x,y,w,h) in faces:\n",
    "                    roi = image_array[y:y+h,x:x+w]\n",
    "                    x_train.append(roi)\n",
    "                    y_labels.append(id_)\n",
    "\n",
    "\n",
    "\n",
    "    #print(y_labels)\n",
    "    #print(x_train)\n",
    "\n",
    "    with open(\"labels.pkl\",'wb')as f:\n",
    "        pickle.dump(label_ids, f)\n",
    "\n",
    "    recognizer.train(x_train, np.array(y_labels))\n",
    "    recognizer.save(\"trainer.yml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OCVFR():\n",
    "    #Face_Detection\n",
    "    #face2_cascade = cv2.CascadeClassifier('cascade/data/haarcascade_frontalface_alt2.xml') #While\n",
    "    face_cascade = cv2.CascadeClassifier('cascade/data/haarcascade_frontalface_default.xml') #Yellow\n",
    "\n",
    "    #Face_Recognition\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create(radius=1, neighbors=8, grid_x=8, grid_y=8) ##OpenCV Recognizer \n",
    "    recognizer.read(\"trainer.yml\")\n",
    "\n",
    "    labels={}\n",
    "    with open(\"labels.pkl\",'rb')as f:\n",
    "        og_labels = pickle.load(f)\n",
    "        labels = {v:k for k,v in og_labels.items()} \n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    pic_marker = 0\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        ret, sf = cap.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #    faces2 = face2_cascade.detectMultiScale(gray,scaleFactor=1.5, minNeighbors=5)\n",
    "        faces = face_cascade.detectMultiScale(gray,scaleFactor=1.5, minNeighbors=5)\n",
    "\n",
    "        #front_face\n",
    "        for (x,y,w,h) in faces:\n",
    "            print(x,y,w,h)\n",
    "            roi_gray = gray[y:y+h, x:x+w] #[Y+heigh, X+width]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "            id_, conf = recognizer.predict(roi_gray)\n",
    "\n",
    "            if conf>=65: #and conf <= 85:\n",
    "                #print(id_)\n",
    "                #print(labels[id_])\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                name = labels[id_]\n",
    "                color = (255,255,255)\n",
    "                stroke = 2\n",
    "                cv2.putText(frame, name, (x,y), font,1,color,stroke, cv2.LINE_AA)\n",
    "\n",
    "    ##   for (x2,y2,w2,h2) in faces2:\n",
    "    ##        print(x2,y2,w2,h2)\n",
    "    ##        roi_gray2 = gray[y2:y2+h2, x2:x2+w2] #[Y+heigh, X+width]\n",
    "    ##        roi_color2 = frame[y2:y2+h2, x2:x2+w2]\n",
    "    ##        \n",
    "    ##        #recognize ? deep learning, keras, tensorflow, scikit learn\n",
    "    ##        \n",
    "    ##        id_2, conf2 = recognizer.predict(roi_gray2)\n",
    "    ##        \n",
    "    ##        if conf2>=65: #and conf <= 85:\n",
    "    ##            #print(id_)\n",
    "    ##            #print(labels[id_])\n",
    "    ##            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    ##            name = labels[id_]\n",
    "    ##            color = (0,255,255)\n",
    "    ##            stroke = 2\n",
    "    ##            cv2.putText(frame, name, (x2,y2), font,1,color,stroke, cv2.LINE_AA)\n",
    "    ##            \n",
    "\n",
    "\n",
    "            img_s = \"\" #Nombre \"\"+pic_marker+\".png\"\n",
    "\n",
    "            #img_item = \"my_image.png\"\n",
    "            #cv2.imwrite(img_item,roi_gray)\n",
    "\n",
    "            #print_rectangle\n",
    "\n",
    "            color = (255,0,0) #BGR 0 - 255\n",
    "            stroke = 2\n",
    "            width = x+w\n",
    "            height = y+h\n",
    "\n",
    "            cv2.rectangle(frame,(x,y),(width,height), color, stroke)\n",
    "\n",
    "    ##        color = (255,0,0) #BGR 0 - 255\n",
    "    ##        stroke = 2\n",
    "    ##        width2 = x2+w2\n",
    "    ##        height2 = y2+h2\n",
    "    ##        \n",
    "    ##        cv2.rectangle(frame,(x2,y2),(width2,height2), color, stroke)\n",
    "\n",
    "\n",
    "        if cv2.waitKey(20) & 0xFF == ord('p'): #Take a picture \n",
    "            cv2.imwrite(img_s+str(pic_marker)+\".png\",sf)\n",
    "            pic_marker = pic_marker+1\n",
    "\n",
    "        cv2.imshow('frame',frame)              #Exit Program\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R\\Desktop\\Inteligencia Artificial\\OCVFR/images\n"
     ]
    }
   ],
   "source": [
    "Face_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287 238 182 182\n",
      "271 234 182 182\n",
      "270 234 182 182\n",
      "272 238 182 182\n",
      "273 239 182 182\n",
      "267 138 182 182\n",
      "272 174 182 182\n",
      "268 139 182 182\n",
      "264 128 182 182\n",
      "262 133 182 182\n",
      "267 139 182 182\n",
      "276 147 182 182\n",
      "257 384 81 81\n",
      "275 149 182 182\n",
      "276 155 182 182\n",
      "280 154 182 182\n",
      "278 156 182 182\n",
      "282 155 182 182\n",
      "281 146 182 182\n",
      "278 148 182 182\n",
      "278 146 182 182\n",
      "277 137 182 182\n",
      "276 141 182 182\n",
      "276 147 182 182\n",
      "273 151 182 182\n",
      "277 156 182 182\n",
      "272 161 182 182\n",
      "271 161 182 182\n",
      "270 162 182 182\n",
      "272 162 182 182\n",
      "272 161 182 182\n",
      "272 159 182 182\n",
      "274 161 182 182\n",
      "272 151 182 182\n",
      "273 152 182 182\n",
      "271 151 182 182\n",
      "271 151 182 182\n",
      "272 152 182 182\n",
      "272 152 182 182\n",
      "273 152 182 182\n",
      "273 152 182 182\n",
      "272 152 182 182\n",
      "273 152 182 182\n",
      "274 150 182 182\n",
      "272 152 182 182\n",
      "271 153 182 182\n",
      "273 149 182 182\n",
      "273 150 182 182\n",
      "271 150 182 182\n",
      "270 150 182 182\n",
      "269 149 182 182\n",
      "273 150 182 182\n",
      "271 152 182 182\n",
      "272 154 182 182\n",
      "273 153 182 182\n",
      "274 152 182 182\n",
      "276 153 182 182\n",
      "280 153 182 182\n",
      "283 155 182 182\n",
      "283 153 182 182\n",
      "282 156 182 182\n",
      "282 158 182 182\n",
      "282 158 182 182\n",
      "284 160 182 182\n",
      "284 158 182 182\n",
      "284 157 182 182\n",
      "283 156 182 182\n",
      "283 156 182 182\n",
      "285 156 182 182\n",
      "282 157 182 182\n",
      "285 154 182 182\n",
      "284 153 182 182\n",
      "282 154 182 182\n",
      "285 154 182 182\n",
      "285 159 182 182\n",
      "290 165 182 182\n",
      "290 192 182 182\n",
      "292 206 182 182\n",
      "296 206 182 182\n",
      "285 173 182 182\n",
      "277 167 182 182\n",
      "274 161 182 182\n",
      "275 164 182 182\n",
      "276 164 182 182\n",
      "277 165 182 182\n",
      "275 167 182 182\n",
      "276 167 182 182\n",
      "277 166 182 182\n",
      "275 167 182 182\n",
      "276 162 182 182\n",
      "276 166 182 182\n",
      "275 167 182 182\n",
      "274 166 182 182\n",
      "275 169 182 182\n",
      "275 167 182 182\n",
      "276 168 182 182\n",
      "276 169 182 182\n",
      "275 169 182 182\n",
      "280 172 182 182\n",
      "282 167 182 182\n",
      "280 169 182 182\n",
      "277 169 182 182\n"
     ]
    }
   ],
   "source": [
    "OCVFR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
